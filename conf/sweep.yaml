program: prep_and_run.py
project: RL for Segmentation
name: sweep_gnn_depths_size
method: bayes
metric:
  name: validation_reward
  goal: maximize

parameters:
  gnn_n_hidden:
    desc: number of hidden layers in graph conv blocks
    values: [2, 4]
  gnn_hl_factor:
    desc: factor by which feature size of hidden featuremaps in gnn increases/decreases
    values: [64, 128, 256]
  gnn_act_depth:
    desc: num of graph convs (1, 2, 3)
    values: [1, 2, 3]
  gnn_act_norm_inp:
    desc: put hidden features on unit sphere and scale by sim
    values: [false, true]
  gnn_crit_depth:
    desc: num of graph convs (1, 2)
    values: [1, 2]
  gnn_crit_norm_inp:
    desc: put hidden features on unit sphere and scale by sim
    values: [false, true]
#  t_max:
#    desc: Mem size in replay memory buffer
#    value: 150
#  data_update_frequency:
#    desc: update env data after n steps
#    value: 50
#  n_updates_per_step:
#    desc: perform n optim steps per env step
#    value: 10
#  batch_size:
#    desc: num samples in minibatch
#    value: 10
#
#  lr_sched:
#    desc: config for moving averages and learning rate sheduling
#    value:
#      mov_avg_bandwidth: 40
#      weight_range: [0.1, 1.0]
#      step_frequency: 10
#      mov_avg_offset: 10
#      torch_sched:  # conf for torch reduceOnPlateau scheduler
#        patience: 1000
#        min_lr: 0.0001
#        factor: 0.05
#        threshold: 0.01
#
#  reward_function:
#    desc: one of sub_graph_dice, artificial_cells, artificial_cells_EllipticFit
#    value: sub_graph_dice
#  s_subgraph:
#    desc: subgraph sizes
#    value: [4, 8, 16] # [8, 16, 32, 64]
#  entropy_range:
#    desc: range of the min entropy constraint
#    value: [0.05, 2.0]
#  init_temperature:
#    desc: initial temperature in Gibbs distribution
#    value: 0.1
#  alpha_lr:
#    desc: learning rate for alpha opt
#    value: 0.1
#  actor_lr:
#    desc: learning rate for actor opt
#    value: 0.0001
#  actor_update_frequency:
#    desc: optim every n-th step
#    value: 1
#  critic_lr:
#    desc: learning rate for critic opr
#    value: 0.0001
#  critic_tau:
#    desc: update weight for target update
#    value: 0.005
#  critic_target_update_frequency:
#    desc: update critic target every nth step
#    value: 5
#
#  use_closed_form_entropy:
#    desc: since we have normal distributions we can use a closed for entropy
#    value: true
#  side_loss_weight:
#    desc: loss weight for the edge-gnn side loss
#    value: 0
