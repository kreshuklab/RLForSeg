# @package _group_
# specific confics for the sac algorithm
reward_function: sub_graph_dice #Reward function: sub_graph_dice, fully_supervised, defining_rules, defining_rules_lg,defining_rules_edge_based
s_subgraph: [4, 8, 16] # [8, 16, 32, 64] # subgraph sizes
entropy_range: [0.05, 2.0]  # min entropy that prediction is allowed to converge to
discount: 0.99  # discount factor (commonly referred to as \gamma in RL)
init_temperature: 0.1  # initial temperature in Gibbs distribution
temperature_regulation: optimized #constant/follow_quality/optimized
# Adam optim conf
alpha_lr: 1e-1
alpha_betas: [0.9, 0.999]
actor_lr: 1e-4
actor_betas: [0.9, 0.999]
actor_update_frequency: 1  # optim step every n-th step
n_actions: 2
critic_lr: 1e-4
critic_betas: [0.9, 0.999]
critic_tau: 0.005
critic_target_update_frequency: 5  # optim step every n-th step

use_closed_form_entropy: true  # uses closed form entropy in critic update (currently for normal distributions only)
sl_beta: 10  # weight for side loss
diag_gaussian_actor:  # specification of multinomial gaussian, acting as policy
  std_bounds: [0.01, 3.0]
  mu_bounds: [-5, 5]
  sample_factor: 0.5  # samples before scaling and offset are in [0, 1]
  sample_offset: 0.0

