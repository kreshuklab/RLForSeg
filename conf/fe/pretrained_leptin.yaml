# @package _group_
# feature extractor
model_name: /g/kreshuk/hilt/storage/leptin_data_nets/fe_l2_ls.pth
load_pretrained: true
optim: "none"  # none/rl_loss  # optimize feature extractor with ril loss, fe extractor optimization works only when fe is part of the agent (MC). In the embedding space environment fe is part of the env

update_frequency: 10 # optim step every n-th step
n_embedding_features: 16  # number of embedding feature channels
contrastive_delta_dist: 0.3
contrastive_delta_var: 0.1
distance: l2  # if none defaults to l2, distance in embedding space
backbone:
  name: UNet2D
  in_channels: 1
  out_channels: 16
  # use Groupnorm instead of Batchnorm for DSB; Batchnorm introduces artifacts around nuclei due to the difference
  # in intensity distribution between images with large and small cells
  layer_order: gcr
  num_groups: 8
  f_maps: [8, 32, 64, 128, 256]
  #conv_padding: 0
  final_sigmoid: false
  is_segmentation: false

#warmup:  # the feature extractor might need pretraining to produce meaningful features
#  # Adam optim conf
#  lr: 1e-4
#  betas: [0.9, 0.999]
#
#  method: 'affinity_contrast'
#  n_iterations: 2000 # number of iterations of feature extrqactor warmup
#  batch_size: 10  # batch size for feature extractor warmup
#
#  patch_manager:
#    name: no_cross # rotated, no_cross, none
#    patch_shape: [256, 256]
#    patch_stride: [16, 16]
#    reorder_sp: true


